%! TEX root = diss.tex
\documentclass[../diss.tex]{subfiles}
\chapter{Introduction}

% Clear motiviation, justing potential benefits of success
% How does work fit into areae of compsci
% related work
% Aim for 500 words here...

% intro to intro, one sentence descriving whole project; implemented simulator,
% then developed algo on top, tested on different graphs, random and also a
% large california real world dataset, tested and evaluated
The dissertation proposes using an algorithm based on matrix multiplication for
solving \ac{APSP}, and aims to demonstrate that parallel computation has significant
benefit for solving \ac{APSP}  on real-world graphs.  With this
goal, I simulate a parallel system with characteristics based on real hardware.
The simulator provides an expressive interface for developing parallel
applications, which is used to implement the \ac{APSP} algorithm. I then
evaluate the algorithm through execution-time measures and other tests. The
overall project has been a great success as both the base success criteria and
several extensions were achieved.

% speeding up computation with parallelism:
% * stop to moore's law, but multiple processors have more agg. performance per
%   power consumption
% * many different kind of parallel systems common today
% * given a sequential algorithm to solve a problem, limit to how efficiently
%   utilize resources, compiler optimisations, limtied beneift
% * need to redesign algorithm with parallelism in mind

% why APSP:
% * pathfinding usable in many different domains, planning routes in transport
%   networks, route packets across internet to minimize some metric, planning
%   actions in AI

% something about how large benefit is when large problem sizes, but keep
% parallel system same
\section{Motivation and aims}%
\label{sec:Motivation}

\subsection{Parallel computation}%
\label{sub:Parallel computation}

Since the 1970s, there has been a yearly exponential increase in the
number of transistors in integrated circuits, thanks to Moore's law
\cite{karlRupp}.
However, around 2006, Dennard scaling started to break down, which meant that
the increase in transistor density did not directly translate to an increase in
performance per watt on a single processor \cite{bohr}.
As a result, performance improvements had to be achieved through other means.
The innovation of multi-core processors allowed the aggregated performance per
watt to keep increasing through combining many \acp{PE}.
Since then, several other ways of distributing computation over many \acp{PE}
have been used, leading to the vast landscape of parallel systems we see today.

Designing algorithms to efficiently utilise 
the computational resources of parallel systems
is important. There is a limit to how much
automatic parallelisation can increase the performance of a
serial algorithm.
 Therefore, the performance of such algorithms will not scale well with the current trends in
processor manufacturing. Instead, one should go back to the problem at hand
and redesign an algorithm with parallel computation in mind. That way, one can
fully utilise the available \acp{PE} and increase performance to a high
degree.

\subsection{The all-pairs shortest path problem}%
\label{sub:The all-pairs shortest path problem}
\vspace{-1pt}

In the shortest path problem, the goal is finding the \textit{shortest path} in
a graph $G=(V,E,w)$ from vertex $i$ to vertex $j$. In the
\ac{APSP} variant of the problem, we want to find the shortest paths between
all pairs of vertices $(i,j) \in V^2$. By working with weighted graphs, a
path-finding algorithm can be applied in many different areas. For example, it
can be used for planning routes in transport networks, routing packets across the
Internet according to some metric, or to plan a robot's movement.

\vspace{-1pt}
\subsection{Related work and proposed analysis}%
\label{sub:Related work}
\vspace{-1pt}

There is a plethora of different parallel algorithms for solving route-planning
problems \cite{astar,parallelDijkstra,floydScale,scalability,experimentalAnalysis}.
However, the evaluation of the proposed or surveyed
algorithms differ greatly from paper to paper. In some research, the analysis
of how the execution time scales with the problem size is mostly based on 
the algorithm's asymptotic complexity
\cite{scalability,parallelDijkstra}. \citeauthor{experimentalAnalysis} and
\citeauthor{floydScale} have analysed the performance of their algorithms through
experiments, but they did not run them on more than 256 \acp{PE}.
Additionally, their input graphs were dense, randomly-generated graphs, that
were not based on real-world graphs such as road-networks.

This project aims to analyse the scaling of a parallel algorithm for solving
\ac{APSP} on real-world-like graphs, using a simulation of a parallel system
with a massive number of \acp{PE}. The project will also investigate
the benefit of parallel execution for different problem sizes and parallel
systems, considering both the number of \acp{PE} and the class of the parallel
system.


% attemts at paralleising route-planning algorithms
% A*: https://arxiv.org/abs/1708.05296
% Dijkstra \cite{parallelDijkstra}
% FloydWarshall: servlets purl one

% also many paralleisation of matrix multiplication
% berntsen, 

% also work on analysing how well these algorithm scale, but mostly based on
% models created from the asymptotic complexity of the algorithms:
% 
% theoretical predictions on performance scalability
% https://www.sciencedirect.com/science/article/pii/074373159190083L?via%3Dihub
% parallelDijkstra
% or experimental, but limited in number of processing elements
% \cite{experimentalAnalysis,floydScale}
% https://www.osti.gov/servlets/purl/1814306
% https://dl.acm.org/doi/abs/10.1145/3229710.3229730


% Use a small number of threads (< 50)
% All the way up to 256, but use dense random graphs ??? not real-world graphs?
% https://www.osti.gov/servlets/purl/1814306
% Mostly focused on asynptotic time analysis
% parallel dijkstra
% http://ilpubs.stanford.edu:8090/59/1/1994-25.pdf
% \cite{berntsen}

% Overview of the whole dissertation
% * summary of work completed
% * (structure of how worked as done, mixing prep. and implm.)
% * roadmap for dissertation, how go about presenting work, what is in diff. chaps
% * s

\vspace{-2pt}
\section{Project structure}%
\label{sec:Project structure}
\vspace{-2pt}

In the Preparation chapter, I give an overview of the different types of parallel
systems as well as listing the assumptions I made for the system to be
simulated. The concept behind the \ac{APSP} algorithm is briefly explained as well.
Afterwards,
I present an analysis of the requirements of each component to
be implemented, and cover the tools and engineering techniques I will use during
the implementation phase. 

In the Implementation chapter, I cover the graph datasets used. Then I explain
the parallel system simulation in a top-down fashion, emphasizing the interface
it provides to the programmer. I then move onto explaining the algorithm
for solving \ac{APSP}, how it was parallelised, and how it was further optimised
by compressing the input graph. Before any code was written, I studied
a lot of theory behind this algorithm, but this is presented together with
its implementation.

In the evaluation chapter, I relate the implemented components to the corresponding
success criteria. I also reference several tests used to justify the
correctness of the software produced. Afterwards, I present plots of the
runtime measurements and use these to discuss the advantage of parallel
computation for solving \ac{APSP}.
